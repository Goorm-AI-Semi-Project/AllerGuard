{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea17106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ==============================================================\n",
    "#  알레르기 분석 서비스 (OCR → Regex → RAG → Zero-shot Fallback)\n",
    "#  + 원재료명 섹션 성분별 알레르기 판정표 생성\n",
    "# ==============================================================\n",
    "\n",
    "import os, io, json, re, logging, unicodedata\n",
    "from typing import List, Set, TypedDict\n",
    "try:\n",
    "    from typing import NotRequired\n",
    "except ImportError:\n",
    "    NotRequired = None\n",
    "\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "from google.cloud import vision\n",
    "from google.oauth2 import service_account\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a42f3dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 🚀 알레르기 분석 서비스 (OCR + RAG + ZS-Fallback + per-ingredient) 시작 ---\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s | %(message)s\")\n",
    "print(\"--- 🚀 알레르기 분석 서비스 (OCR + RAG + ZS-Fallback + per-ingredient) 시작 ---\")\n",
    "\n",
    "# --- 표준 알레르기 / 필터 / 동의어 ---\n",
    "ALLERGENS_STD_SET = {\n",
    "    \"알류\", \"우유\", \"메밀\", \"땅콩\", \"대두\", \"밀\", \"잣\", \"호두\",\n",
    "    \"게\", \"새우\", \"오징어\", \"고등어\", \"조개류\", \"복숭아\", \"토마토\",\n",
    "    \"닭고기\", \"돼지고기\", \"쇠고기\", \"아황산류\"\n",
    "}\n",
    "IGNORE_KEYWORDS = {\n",
    "    '열량','탄수화물','단백질','지방','당류','나트륨','콜레스테롤','포화지방','트랜스지방','내용량','I','II'\n",
    "}\n",
    "ALIAS_MAP = {\n",
    "    # 알류\n",
    "    \"계란\":\"알류\",\"달걀\":\"알류\",\"난백\":\"알류\",\"난황\":\"알류\",\n",
    "    # 우유\n",
    "    \"유청\":\"우유\",\"유청분말\":\"우유\",\"유청단백\":\"우유\",\"카제인나트륨\":\"우유\",\"치즈\":\"우유\",\"버터\":\"우유\",\"크림\":\"우유\",\"분유\":\"우유\",\"탈지분유\":\"우유\",\n",
    "    # 대두/밀/메밀\n",
    "    \"대두레시틴\":\"대두\",\"대두단백\":\"대두\",\"소이프로틴\":\"대두\",\n",
    "    \"밀가루\":\"밀\",\"메밀가루\":\"메밀\",\n",
    "    # 육류\n",
    "    \"소고기\":\"쇠고기\",\"소 육\":\"쇠고기\",\"우육\":\"쇠고기\",\"돼지\":\"돼지고기\",\"돈육\":\"돼지고기\",\"닭\":\"닭고기\",\"계육\":\"닭고기\",\n",
    "    # 견과/어패류 변형\n",
    "    \"호두분말\":\"호두\",\"잣가루\":\"잣\",\"새우가루\":\"새우\",\"오징어분말\":\"오징어\",\n",
    "    # 과채\n",
    "    \"토마토페이스트\":\"토마토\"\n",
    "}\n",
    "def alias_to_std(name: str) -> str:\n",
    "    key = name.replace(\" \",\"\")\n",
    "    for k,v in ALIAS_MAP.items():\n",
    "        if k in key:\n",
    "            return v\n",
    "    return name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec90e8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 임베딩 모델 로드: distiluse-base-multilingual-cased-v1\n",
      "INFO | Use pytorch device_name: cpu\n",
      "INFO | Load pretrained SentenceTransformer: distiluse-base-multilingual-cased-v1\n",
      "Device set to use cpu\n",
      "INFO | Zero-shot 모델 사용: MoritzLaurer/deberta-v3-large-zeroshot-v2.0 (device=-1)\n",
      "INFO | GCP Vision 클라이언트 준비 완료\n",
      "INFO | KB 캐시 로드 완료: 702개 항목\n"
     ]
    }
   ],
   "source": [
    "# --- 글로벌 리소스 로드 ---\n",
    "try:\n",
    "    EMBEDDING_MODEL_NAME = 'distiluse-base-multilingual-cased-v1'\n",
    "    logging.info(f\"임베딩 모델 로드: {EMBEDDING_MODEL_NAME}\")\n",
    "    embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "\n",
    "    ZSL_MODEL_CANDIDATES = [\n",
    "        \"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\",\n",
    "        \"joeddav/xlm-roberta-large-xnli\"\n",
    "    ]\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    nli_pipeline = None\n",
    "    for name in ZSL_MODEL_CANDIDATES:\n",
    "        try:\n",
    "            nli_pipeline = pipeline(\"zero-shot-classification\", model=name, device=device)\n",
    "            logging.info(f\"Zero-shot 모델 사용: {name} (device={device})\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"{name} 로드 실패: {e}\")\n",
    "    if nli_pipeline is None:\n",
    "        logging.warning(\"Zero-shot 모델 로드 실패 → Fallback 비활성\")\n",
    "\n",
    "    KEY_JSON_PATH_DEFAULT = r\"D:\\key folder\\ocr-project-470906-7ffeebabeb09.json\"  # 필요시 교체\n",
    "    KEY_JSON_PATH = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\", KEY_JSON_PATH_DEFAULT)\n",
    "    vision_client = None\n",
    "    try:\n",
    "        credentials = service_account.Credentials.from_service_account_file(KEY_JSON_PATH)\n",
    "        vision_client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "        logging.info(\"GCP Vision 클라이언트 준비 완료\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"GCP Vision 초기화 실패: {e} → 로컬 OCR Fallback만 사용\")\n",
    "\n",
    "    KB_EMB_PATH = \"kb_embeddings.npy\"\n",
    "    KB_CAT_PATH = \"kb_categories.json\"\n",
    "    kb_embeddings = np.load(KB_EMB_PATH)\n",
    "    with open(KB_CAT_PATH,\"r\",encoding=\"utf-8\") as f:\n",
    "        kb_categories = json.load(f)\n",
    "    assert kb_embeddings.shape[0] == len(kb_categories), \\\n",
    "        f\"KB 불일치: emb={kb_embeddings.shape[0]} vs cat={len(kb_categories)}\"\n",
    "    logging.info(f\"KB 캐시 로드 완료: {len(kb_categories)}개 항목\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"글로벌 설정 실패: {e}\")\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0f22d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 임계값/템플릿 ---\n",
    "RAG_CONFIDENCE_THRESHOLD = float(os.getenv(\"RAG_THRESHOLD\",\"0.85\"))\n",
    "NLI_FALLBACK_THRESHOLD   = float(os.getenv(\"NLI_THRESHOLD\",\"0.5\"))\n",
    "HYPOTHESIS = \"{} 알레르기(유발) 성분이다.\"\n",
    "\n",
    "# --- 로컬 OCR Fallback(옵션) ---\n",
    "def local_ocr_fallback(img_path: str) -> str:\n",
    "    try:\n",
    "        import easyocr\n",
    "        reader = easyocr.Reader(['ko','en'])\n",
    "        lines = reader.readtext(img_path, detail=0)\n",
    "        return \"\\n\".join(lines)\n",
    "    except Exception:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67c496f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 상태 정의 (★ per-ingredient 필드 추가) ---\n",
    "class AllergyGraphState(TypedDict):\n",
    "    image_path: str\n",
    "    raw_ocr_text: str\n",
    "    ingredients_to_check: deque\n",
    "    current_ingredient: str\n",
    "    rag_result: dict\n",
    "    final_allergens: Set[str]\n",
    "    final_output_json: str\n",
    "    # [ADDED] 아래 5개\n",
    "    ingredients_from_section: NotRequired[List[str]] if NotRequired else list  # 원재료명 목록\n",
    "    declared_allergens: NotRequired[List[str]] if NotRequired else list        # '...함유' 명시 목록(표준화)\n",
    "    coi_phrases: NotRequired[List[str]] if NotRequired else list               # 교차오염 문구\n",
    "    per_ingredient_results: NotRequired[List[dict]] if NotRequired else list   # 성분별 판정표\n",
    "    current_raw_ingredient: NotRequired[str] if NotRequired else str           # 원문 성분\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d6cb98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 노드 ---\n",
    "\n",
    "def call_gcp_vision_api(state: AllergyGraphState) -> AllergyGraphState:\n",
    "    img_path = state['image_path']\n",
    "    logging.info(f\"[Node1] OCR 호출: {img_path}\")\n",
    "    text = \"\"\n",
    "    if vision_client is not None:\n",
    "        try:\n",
    "            with io.open(img_path,'rb') as f:\n",
    "                image = vision.Image(content=f.read())\n",
    "            res = vision_client.text_detection(image=image)\n",
    "            if res.error.message:\n",
    "                raise RuntimeError(res.error.message)\n",
    "            text = res.full_text_annotation.text or \"\"\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"GCP OCR 실패: {e}\")\n",
    "    if not text.strip():\n",
    "        lt = local_ocr_fallback(img_path)\n",
    "        if lt.strip():\n",
    "            logging.info(\"로컬 OCR Fallback 사용\")\n",
    "            text = lt\n",
    "    if not text.strip():\n",
    "        logging.warning(\"OCR 결과가 비어있음\")\n",
    "    return {**state, \"raw_ocr_text\": text}\n",
    "\n",
    "def parse_text_from_raw(state: AllergyGraphState) -> AllergyGraphState:\n",
    "    \"\"\"[REPLACED] Regex 파서 + 원재료명/함유/COI 분리 수집\"\"\"\n",
    "    raw_text = state.get('raw_ocr_text','') or ''\n",
    "    if not raw_text.strip():\n",
    "        return {**state, \"ingredients_to_check\": deque(), \"final_allergens\": set(),\n",
    "                \"ingredients_from_section\": [], \"declared_allergens\": [], \"coi_phrases\": [],\n",
    "                \"per_ingredient_results\": []}\n",
    "\n",
    "    text = unicodedata.normalize(\"NFKC\", raw_text).replace(\"\\n\",\" \")\n",
    "\n",
    "    # (1) 원재료명 블록\n",
    "    pat_ing = re.compile(\n",
    "        r\"원재료(?:명| 및[^:]{0,10}|/[^:]{0,10})?\\s*[:：]\\s*(.+?)(?:알레르기|영양정보|영양성분|함유|품목보고|고객상담|소비기한|$)\",\n",
    "        re.S\n",
    "    )\n",
    "    ingredients_from_section: List[str] = []\n",
    "    m = pat_ing.search(text)\n",
    "    if m:\n",
    "        blob = m.group(1)\n",
    "        raw_items = [s.strip() for s in blob.split(',') if s.strip()]\n",
    "        cleaned = []\n",
    "        for it in raw_items:\n",
    "            it = it.split('(')[0].strip()\n",
    "            if any(it.startswith(k) for k in IGNORE_KEYWORDS):\n",
    "                continue\n",
    "            cleaned.append(it)\n",
    "        ingredients_from_section = cleaned\n",
    "        logging.info(f\"[Node2] 원재료 {len(cleaned)}개 추출: {cleaned[:12]}{'...' if len(cleaned)>12 else ''}\")\n",
    "    else:\n",
    "        logging.info(\"[Node2] 원재료명 블럭을 찾지 못함\")\n",
    "\n",
    "    # (2) '...함유' (알레르기 유발물질: … 함유 포함)\n",
    "    pat_contains = re.compile(r\"(?:알레르기\\s*(?:유발)?\\s*물질[:：]?\\s*)?([가-힣,\\s]+?)\\s*함유\")\n",
    "    declared_allergens = []\n",
    "    m2 = pat_contains.search(text)\n",
    "    if m2:\n",
    "        contains_list = [s.strip() for s in m2.group(1).split(',') if s.strip()]\n",
    "        logging.info(f\"[Node2] '함유' 섹션 {len(contains_list)}개: {contains_list}\")\n",
    "        # [ADDED] 표준화(달걀→알류 등) + 표준 집합 필터\n",
    "        for item in contains_list:\n",
    "            std = alias_to_std(item)\n",
    "            if std in ALLERGENS_STD_SET:\n",
    "                declared_allergens.append(std)\n",
    "\n",
    "    # (3) COI(교차오염) 문구 추출\n",
    "    coi_phrases = []\n",
    "    for pat in [r\"같은\\s*제조(?:시설|라인|설비)\", r\"교차오염\", r\"혼입\\s*가능\", r\"함유\\s*가능\"]:\n",
    "        for mm in re.finditer(pat, text):\n",
    "            s = max(0, text.rfind('.', 0, mm.start()))\n",
    "            e = text.find('.', mm.end())\n",
    "            coi_phrases.append(text[s+1:e if e!=-1 else mm.end()+30].strip())\n",
    "\n",
    "    # 큐는 “원재료명 성분만” 대상으로 분류 루프 수행\n",
    "    q = deque(ingredients_from_section)\n",
    "\n",
    "    # 명시된 알레르겐은 즉시 누적(최종에서 합집합)\n",
    "    found_set = set(declared_allergens)\n",
    "\n",
    "    return {**state,\n",
    "            \"ingredients_to_check\": q,\n",
    "            \"final_allergens\": found_set,\n",
    "            \"ingredients_from_section\": ingredients_from_section,\n",
    "            \"declared_allergens\": declared_allergens,\n",
    "            \"coi_phrases\": coi_phrases,\n",
    "            \"per_ingredient_results\": []}\n",
    "\n",
    "\n",
    "def prepare_next_ingredient(state: AllergyGraphState) -> AllergyGraphState:\n",
    "    \"\"\"[REPLACED] 다음 성분 추출 + alias 표준화 필드 유지\"\"\"\n",
    "    q = state['ingredients_to_check']\n",
    "    if not q:\n",
    "        return state\n",
    "    raw = q.popleft()\n",
    "    std = alias_to_std(raw)\n",
    "    return {**state,\n",
    "            \"current_raw_ingredient\": raw,        # [ADDED]\n",
    "            \"current_ingredient\": std}            # 분류는 표준화 텍스트 기준\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33116941",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rag_search(state: AllergyGraphState) -> AllergyGraphState:\n",
    "    \"\"\"Node4: RAG (alias가 곧 표준 알레르겐이면 즉시 확정)\"\"\"\n",
    "    ing_std = state.get('current_ingredient','')\n",
    "    ing_raw = state.get('current_raw_ingredient', ing_std)\n",
    "\n",
    "    # [ADDED] alias로 곧바로 표준 알레르겐이 된 경우: 확정\n",
    "    if ing_std in ALLERGENS_STD_SET:\n",
    "        return {**state, \"rag_result\": {\"confidence\": 1.0, \"found_allergen\": ing_std, \"method\": \"alias\"}}\n",
    "\n",
    "    # 그 외에는 RAG 검색\n",
    "    if not ing_std:\n",
    "        return {**state, \"rag_result\": {\"confidence\": 0.0, \"found_allergen\": \"없음\", \"method\": \"none\"}}\n",
    "\n",
    "    qemb = embedding_model.encode([ing_std])\n",
    "    sims = cosine_similarity(qemb, kb_embeddings)\n",
    "    idx = int(np.argmax(sims[0])); conf = float(sims[0][idx]); found = kb_categories[idx]\n",
    "    logging.info(f\"[Node4] RAG: '{ing_raw}' → '{found}' (sim={conf:.4f})\")\n",
    "    return {**state, \"rag_result\": {\"confidence\": conf, \"found_allergen\": found, \"method\": \"rag\"}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e17e9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_fallback(state: AllergyGraphState) -> AllergyGraphState:\n",
    "    \"\"\"Node5: Zero-shot NLI\"\"\"\n",
    "    ing_std = state.get('current_ingredient','')\n",
    "    if not nli_pipeline or not ing_std:\n",
    "        return {**state, \"rag_result\": {\"confidence\": 1.0, \"found_allergen\": \"없음\", \"method\": \"none\"}}\n",
    "    labels = list(ALLERGENS_STD_SET) + [\"관련 없음\"]\n",
    "    try:\n",
    "        resp = nli_pipeline(ing_std, labels, hypothesis_template=HYPOTHESIS)\n",
    "        top_label, top_score = resp['labels'][0], float(resp['scores'][0])\n",
    "        return {**state, \"rag_result\": {\n",
    "            \"confidence\": top_score,\n",
    "            \"found_allergen\": top_label if top_label in ALLERGENS_STD_SET and top_score>=NLI_FALLBACK_THRESHOLD else \"없음\",\n",
    "            \"method\": \"nli\"\n",
    "        }}\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"[Node5] ZS 오류: {e}\")\n",
    "        return {**state, \"rag_result\": {\"confidence\": 1.0, \"found_allergen\": \"없음\", \"method\": \"none\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c214eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def update_final_list(state: AllergyGraphState) -> AllergyGraphState:\n",
    "    \"\"\"Node6: 결과 취합 + ★성분별 판정표 누적 [CHANGED]\"\"\"\n",
    "    res = state['rag_result']\n",
    "    found = res.get(\"found_allergen\",\"없음\")\n",
    "    conf  = float(res.get(\"confidence\",0.0))\n",
    "    method= res.get(\"method\",\"none\")\n",
    "\n",
    "    # 6-1) 최종 알레르겐 집합(명시 + 추론) 누적\n",
    "    cur_set = state['final_allergens']\n",
    "    if found in ALLERGENS_STD_SET:\n",
    "        cur_set.add(found)\n",
    "\n",
    "    # 6-2) ★ 성분별 판정표에 레코드 추가 (원문/표준/방법/점수/알레르겐여부)\n",
    "    row = {\n",
    "        \"ingredient_raw\": state.get(\"current_raw_ingredient\", state.get(\"current_ingredient\",\"\")),\n",
    "        \"ingredient_std\": state.get(\"current_ingredient\",\"\"),\n",
    "        \"is_allergen\": found in ALLERGENS_STD_SET,\n",
    "        \"allergen\": found if found in ALLERGENS_STD_SET else \"없음\",\n",
    "        \"method\": method,\n",
    "        \"confidence\": round(conf, 4)\n",
    "    }\n",
    "    table = state.get(\"per_ingredient_results\", [])\n",
    "    table.append(row)\n",
    "\n",
    "    return {**state, \"final_allergens\": cur_set, \"per_ingredient_results\": table}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd99899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_processing(state: AllergyGraphState) -> AllergyGraphState:\n",
    "    \"\"\"Node7: 종료 (명시함유 + 추론합집합, COI, per-ingredient 포함)\"\"\"\n",
    "    inferred = set(state.get('final_allergens', set()))\n",
    "    declared = set(state.get('declared_allergens', []))\n",
    "    final_list = sorted(list(inferred.union(declared)))  # 합집합\n",
    "\n",
    "    result = {\n",
    "        \"allergens\": final_list,\n",
    "        \"declared_allergens\": sorted(list(declared)),\n",
    "        \"coi_phrases\": state.get(\"coi_phrases\", []),\n",
    "        \"ingredients\": state.get(\"per_ingredient_results\", [])\n",
    "    }\n",
    "    final_json = json.dumps(result, ensure_ascii=False)\n",
    "    logging.info(f\"[DONE] {final_json}\")\n",
    "    return {**state, \"final_output_json\": final_json}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47a33255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 조건부 엣지 ---\n",
    "def route_rag_result(state: AllergyGraphState) -> str:\n",
    "    conf = float(state['rag_result']['confidence'])\n",
    "    allergen = state['rag_result']['found_allergen']\n",
    "    if conf >= RAG_CONFIDENCE_THRESHOLD and allergen in ALLERGENS_STD_SET:\n",
    "        return \"rag_success\"\n",
    "    return \"needs_llm_fallback\"\n",
    "\n",
    "def check_remaining_ingredients(state: AllergyGraphState) -> str:\n",
    "    q = state.get(\"ingredients_to_check\", deque())\n",
    "    return \"has_more_ingredients\" if q and len(q)>0 else \"all_ingredients_done\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "871863a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | ✅ LangGraph 컴파일 완료\n"
     ]
    }
   ],
   "source": [
    "# --- 그래프 빌드/컴파일 ---\n",
    "workflow = StateGraph(AllergyGraphState)\n",
    "workflow.add_node(\"call_gcp_vision_api\", call_gcp_vision_api)\n",
    "workflow.add_node(\"parse_text_from_raw\", parse_text_from_raw)\n",
    "workflow.add_node(\"prepare_next_ingredient\", prepare_next_ingredient)\n",
    "workflow.add_node(\"rag_search\", rag_search)\n",
    "workflow.add_node(\"llm_fallback\", llm_fallback)\n",
    "workflow.add_node(\"update_final_list\", update_final_list)\n",
    "workflow.add_node(\"finalize_processing\", finalize_processing)\n",
    "\n",
    "workflow.set_entry_point(\"call_gcp_vision_api\")\n",
    "workflow.add_edge(\"call_gcp_vision_api\",\"parse_text_from_raw\")\n",
    "# [REPLACED] parse → prepare를 조건부로 (빈 큐 보호)\n",
    "workflow.add_conditional_edges(\n",
    "    \"parse_text_from_raw\",\n",
    "    check_remaining_ingredients,\n",
    "    {\"has_more_ingredients\":\"prepare_next_ingredient\",\"all_ingredients_done\":\"finalize_processing\"}\n",
    ")\n",
    "workflow.add_edge(\"prepare_next_ingredient\",\"rag_search\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"rag_search\",\n",
    "    route_rag_result,\n",
    "    {\"rag_success\":\"update_final_list\",\"needs_llm_fallback\":\"llm_fallback\"}\n",
    ")\n",
    "workflow.add_edge(\"llm_fallback\",\"update_final_list\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"update_final_list\",\n",
    "    check_remaining_ingredients,\n",
    "    {\"has_more_ingredients\":\"prepare_next_ingredient\",\"all_ingredients_done\":\"finalize_processing\"}\n",
    ")\n",
    "workflow.add_edge(\"finalize_processing\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "logging.info(\"✅ LangGraph 컴파일 완료\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07e1871c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | [Node1] OCR 호출: data/김광무_121.jpg\n",
      "INFO | [Node2] 원재료명 블럭을 찾지 못함\n",
      "INFO | [Node2] '함유' 섹션 5개: ['돼지고기', '대두', '쇠고기', '밀', '우유']\n",
      "INFO | [DONE] {\"allergens\": [\"대두\", \"돼지고기\", \"밀\", \"쇠고기\", \"우유\"], \"declared_allergens\": [\"대두\", \"돼지고기\", \"밀\", \"쇠고기\", \"우유\"], \"coi_phrases\": [\"개 그대로 넣을 경우 터질 우려가 있으니 을 사용한 제품과 같은 제조시설에서 제조하고 있습니다\"], \"ingredients\": []}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 최종 반환 JSON ===\n",
      "{\"allergens\": [\"대두\", \"돼지고기\", \"밀\", \"쇠고기\", \"우유\"], \"declared_allergens\": [\"대두\", \"돼지고기\", \"밀\", \"쇠고기\", \"우유\"], \"coi_phrases\": [\"개 그대로 넣을 경우 터질 우려가 있으니 을 사용한 제품과 같은 제조시설에서 제조하고 있습니다\"], \"ingredients\": []}\n"
     ]
    }
   ],
   "source": [
    "# --- 테스트 실행 ---\n",
    "if __name__ == \"__main__\":\n",
    "    my_test_image_file = \"data/김광무_121.jpg\"  # 필요하면 교체\n",
    "    test_input = {\n",
    "        \"image_path\": my_test_image_file,\n",
    "        \"raw_ocr_text\": \"\",\n",
    "        \"ingredients_to_check\": deque(),\n",
    "        \"current_ingredient\": \"\",\n",
    "        \"rag_result\": {\"confidence\": 0.0, \"found_allergen\": \"없음\", \"method\":\"none\"},\n",
    "        \"final_allergens\": set(),\n",
    "        \"final_output_json\": \"\",\n",
    "        # [ADDED defaults]\n",
    "        \"ingredients_from_section\": [],\n",
    "        \"declared_allergens\": [],\n",
    "        \"coi_phrases\": [],\n",
    "        \"per_ingredient_results\": [],\n",
    "        \"current_raw_ingredient\": \"\"\n",
    "    }\n",
    "    final_state = app.invoke(test_input, {\"recursion_limit\": 100})\n",
    "    print(\"\\n=== 최종 반환 JSON ===\")\n",
    "    print(final_state.get(\"final_output_json\",\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 식품 라벨 분석 파이프라인: OCR 텍스트 추출 및 알레르겐 분석\n",
    "\n",
    "이 노트북은 이미지 형태의 식품 라벨을 분석하는 두 가지 주요 파이프라인을 구현합니다.\n",
    "\n",
    "1.  **단순 텍스트 추출 (OCR → .txt)**: 이미지에서 모든 텍스트를 추출하여 `.txt` 파일로 저장합니다.\n",
    "2.  **알레르겐 분석 (OCR → LLM → .json)**: 이미지의 텍스트를 기반으로 한국 식약처(MFDS) 기준 알레르겐 정보를 분석하고, 구조화된 `.json` 파일로 결과를 저장합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 사전 준비 (Prerequisites)\n",
    "\n",
    "아래 셀을 실행하여 파이프라인에 필요한 모든 라이브러리를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-vision\n",
      "  Downloading google_cloud_vision-3.10.2-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision)\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 (from google-cloud-vision)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-cloud-vision)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-cloud-vision)\n",
      "  Downloading protobuf-6.32.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.32.3)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision)\n",
      "  Downloading grpcio-1.74.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision)\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2025.1.31)\n",
      "Downloading google_cloud_vision-3.10.2-py3-none-any.whl (527 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.9/527.9 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-6.32.0-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpcio-1.74.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m370.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.74.0-py3-none-any.whl (14 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: pyasn1, protobuf, grpcio, cachetools, rsa, pyasn1-modules, proto-plus, googleapis-common-protos, grpcio-status, google-auth, google-api-core, google-cloud-vision\n",
      "Successfully installed cachetools-5.5.2 google-api-core-2.25.1 google-auth-2.40.3 google-cloud-vision-3.10.2 googleapis-common-protos-1.70.0 grpcio-1.74.0 grpcio-status-1.74.0 proto-plus-1.26.1 protobuf-6.32.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 rsa-4.9.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.56.1-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.8.0.dev20250319+cu128)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.9.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch) (77.0.1)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.1.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Downloading transformers-4.56.1-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m398.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
      "Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m275.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m187.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.9.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m799.0/799.0 kB\u001b[0m \u001b[31m311.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m359.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading hf_xet-1.1.9-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m282.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, safetensors, regex, hf-xet, tiktoken, huggingface-hub, tokenizers, transformers, accelerate\n",
      "Successfully installed accelerate-1.10.1 hf-xet-1.1.9 huggingface-hub-0.34.4 regex-2025.9.1 safetensors-0.6.2 tiktoken-0.11.0 tokenizers-0.22.0 tqdm-4.67.1 transformers-4.56.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-vision\n",
    "!pip install transformers accelerate torch tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Cloud Platform (GCP) 인증 설정\n",
    "\n",
    "GCP Vision API를 사용하려면 서비스 계정 키 파일(`.json`)이 필요합니다.\n",
    "아래 코드에서 `YOUR_SERVICE_ACCOUNT_KEY.json` 부분을 실제 키 파일 경로로 수정하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GCP 인증 설정 완료: ocr-project-470906-7ffeebabeb09.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 🚨 중요: 이 부분을 실제 GCP 서비스 계정 키 파일 경로로 변경하세요.\n",
    "key_path = \"ocr-project-470906-7ffeebabeb09.json\"\n",
    "\n",
    "if os.path.exists(key_path):\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = key_path\n",
    "    print(f\"✅ GCP 인증 설정 완료: {key_path}\")\n",
    "else:\n",
    "    print(f\"⚠️ 경고: GCP 인증 키 파일을 찾을 수 없습니다. 경로를 확인하세요: {key_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 라이브러리 임포트 및 전역 설정\n",
    "\n",
    "파이프라인 전체에서 사용할 라이브러리와 주요 설정값을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리\n",
    "import io\n",
    "import json\n",
    "import re\n",
    "import textwrap\n",
    "import argparse\n",
    "from typing import List, Dict, Set\n",
    "\n",
    "# Google Cloud Vision API\n",
    "from google.cloud import vision\n",
    "\n",
    "# Hugging Face Transformers (LLM)\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# --- 전역 설정 ---\n",
    "\n",
    "# 사용할 LLM 모델 이름 (VRAM이 부족하면 더 작은 모델로 변경 가능)\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "# 한국 식약처(MFDS) 고시 알레르겐 표준 명칭\n",
    "MFDS_CANON = [\n",
    "    \"계란(난류)\",\"우유\",\"메밀\",\"땅콩\",\"대두\",\"밀\",\"고등어\",\"게\",\"새우\",\n",
    "    \"돼지고기\",\"복숭아\",\"토마토\",\"아황산류\",\"호두\",\"닭고기\",\"쇠고기\",\n",
    "    \"오징어\",\"조개류\",\"잣\"\n",
    "]\n",
    "\n",
    "# LLM 모델과 토크나이저를 저장할 전역 변수 (메모리에 한 번만 로드하기 위함)\n",
    "_tokenizer = None\n",
    "_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 핵심 기능: 이미지 텍스트 추출 (GCP Vision OCR)\n",
    "\n",
    "이 함수는 두 파이프라인 모두에서 사용하는 가장 기본적인 기능입니다. 이미지 파일 경로를 받아 GCP Vision API를 통해 텍스트를 추출하고 문자열로 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text_by_gcp(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    이미지 파일에서 텍스트를 감지하여 하나의 문자열로 반환합니다.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): 분석할 이미지 파일의 경로.\n",
    "\n",
    "    Returns:\n",
    "        str: 추출된 전체 텍스트. 텍스트가 없으면 빈 문자열을 반환.\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundError: 이미지 파일 경로가 잘못된 경우 발생.\n",
    "        RuntimeError: GCP API 호출 시 에러가 발생한 경우.\n",
    "    \"\"\"\n",
    "    # 1. 파일 존재 여부 확인\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"이미지 파일을 찾을 수 없습니다: {image_path}\")\n",
    "\n",
    "    print(f\"'{os.path.basename(image_path)}' 파일에서 텍스트를 추출합니다...\")\n",
    "    \n",
    "    try:\n",
    "        # 2. GCP Vision 클라이언트 초기화\n",
    "        client = vision.ImageAnnotatorClient()\n",
    "        \n",
    "        # 3. 이미지 파일을 바이너리(binary) 모드로 읽기\n",
    "        with io.open(image_path, \"rb\") as image_file:\n",
    "            content = image_file.read()\n",
    "\n",
    "        # 4. GCP API가 인식할 수 있는 이미지 형식으로 변환\n",
    "        image = vision.Image(content=content)\n",
    "        \n",
    "        # 5. text_detection API 호출\n",
    "        response = client.text_detection(image=image)\n",
    "\n",
    "        # API 응답에 에러 메시지가 있는지 확인\n",
    "        if response.error.message:\n",
    "            raise RuntimeError(\n",
    "                f\"GCP OCR 오류: {response.error.message}\\n\"\n",
    "                \"자세한 내용: https://cloud.google.com/apis/design/errors\"\n",
    "            )\n",
    "\n",
    "        # 6. 결과 파싱\n",
    "        texts = response.text_annotations\n",
    "        if not texts:\n",
    "            print(\"이미지에서 텍스트를 찾지 못했습니다.\")\n",
    "            return \"\"\n",
    "        \n",
    "        print(\"텍스트 추출 완료.\")\n",
    "        # response.text_annotations의 첫 번째 요소(index 0)에 전체 텍스트가 포함됨\n",
    "        return texts[0].description\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"API 호출 중 오류가 발생했습니다: {e}\")\n",
    "        print(\"Google Cloud 인증(GOOGLE_APPLICATION_CREDENTIALS)이 올바르게 설정되었는지 확인하세요.\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 파이프라인 1: 알레르겐 분석 (OCR → LLM → JSON)\n",
    "\n",
    "텍스트 추출 후, LLM을 통해 알레르겐 정보를 분석하고 JSON으로 결과를 정제하는 전체 과정입니다.\n",
    "\n",
    "### 4-1. LLM 로딩 및 프롬프트 정의\n",
    "\n",
    "LLM을 메모리에 로드하고, LLM에게 역할을 부여하는 시스템 프롬프트를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm():\n",
    "    \"\"\"Hugging Face LLM과 토크나이저를 로드합니다. 이미 로드된 경우 건너뜁니다.\"\"\"\n",
    "    global _tokenizer, _model\n",
    "    if _model is None:\n",
    "        print(f\"'{MODEL_NAME}' 모델을 로딩합니다. 잠시 기다려주세요...\")\n",
    "        _tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "        _model = AutoModelForCausalLM.from_pretrained(\n",
    "            MODEL_NAME,\n",
    "            device_map=\"auto\",  # 사용 가능한 GPU/CPU에 자동으로 모델을 할당\n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=\"auto\", # 사용 가능한 하드웨어에 맞춰 데이터 타입 자동 설정\n",
    "        )\n",
    "        print(\"모델 로딩 완료.\")\n",
    "\n",
    "# LLM에게 역할을 부여하고, 출력 형식을 지정하는 시스템 프롬프트\n",
    "SYSTEM_PROMPT = textwrap.dedent(\"\"\"\n",
    "너는 '한국 식품 라벨 분석가'야. 입력은 GCP OCR로 추출한 라벨 텍스트다.\n",
    "목표: 한국 식약처(MFDS) 알레르기 표시 기준 안에서 포함 여부를 판별해 JSON만 출력한다.\n",
    "\n",
    "규칙:\n",
    "- \"알레르기 유발물질\", \"함유\" 등 명시 라인을 최우선으로 사용한다.\n",
    "- 명시 라인이 없으면 원재료명에서 동의어를 근거로 추론한다.\n",
    "- 결과는 반드시 아래 스키마의 JSON 형식으로만 출력하며, 다른 설명은 절대 추가하지 않는다.\n",
    "- evidence는 원문에서 찾은 '최소한의 문자열'만 사용한다. 예: \"우유\", \"치즈분말\".\n",
    "- \"… 대두, 밀, 우유 … 함유\" 문장은 각 알레르겐으로 분할하여 해당 단어만 evidence로 쓴다.\n",
    "\n",
    "JSON 스키마:\n",
    "{\n",
    "  \"allergens_found\": [\n",
    "    {\"canonical\": \"<MFDS 표준명>\", \"evidence\": [\"<근거1>\", \"<근거2>\"]}\n",
    "  ],\n",
    "  \"uncertain_mentions\": [\"<애매하거나 교차오염 가능성 표기>\"],\n",
    "  \"notes\": \"<판별 근거 요약(한 줄)>\"\n",
    "}\n",
    "\"\"\").strip()\n",
    "\n",
    "def build_user_prompt(ocr_text: str) -> str:\n",
    "    \"\"\"OCR 텍스트를 받아 LLM에게 전달할 최종 사용자 프롬프트를 생성합니다.\"\"\"\n",
    "    return textwrap.dedent(f\"\"\"\n",
    "    다음은 GCP Vision OCR로 추출한 식품 라벨 텍스트입니다.\n",
    "    시스템 프롬프트의 규칙을 적용해 JSON만 출력해 주세요.\n",
    "\n",
    "    [OCR_TEXT_START]\n",
    "    {ocr_text.strip()}\n",
    "    [OCR_TEXT_END]\n",
    "    \"\"\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. LLM 추론 및 결과 파싱\n",
    "\n",
    "LLM을 실행하고, 모델이 생성한 텍스트 응답에서 깨끗한 JSON 데이터만 안전하게 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_infer_to_json(ocr_text: str) -> Dict:\n",
    "    \"\"\"OCR 텍스트로 LLM 추론을 실행하고, 결과 텍스트를 JSON(Dict)으로 파싱합니다.\"\"\"\n",
    "    load_llm() # 모델이 로드되었는지 확인\n",
    "    \n",
    "    # 시스템 프롬프트와 사용자 프롬프트를 LLM이 이해하는 대화 형식으로 조합\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": build_user_prompt(ocr_text)}\n",
    "    ]\n",
    "    prompt = _tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "    # 텍스트를 모델이 처리할 수 있는 텐서(Tensor)로 변환\n",
    "    inputs = _tokenizer(prompt, return_tensors=\"pt\").to(_model.device)\n",
    "    \n",
    "    # LLM 텍스트 생성 실행\n",
    "    outputs = _model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=800,   # 최대 생성 토큰 수\n",
    "        do_sample=False,      # 항상 가장 확률 높은 단어만 선택 (결과의 일관성 확보)\n",
    "        temperature=0.0,      # 창의성 0 (결과의 일관성 확보)\n",
    "        eos_token_id=_tokenizer.eos_token_id,\n",
    "    )\n",
    "    \n",
    "    # 생성된 텐서를 다시 사람이 읽을 수 있는 텍스트로 변환\n",
    "    full_response = _tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # 모델 응답 부분만 잘라내기\n",
    "    assistant_response = full_response.split(\"assistant\\n\")[-1].strip()\n",
    "    \n",
    "    # 텍스트에서 JSON 부분만 안전하게 파싱\n",
    "    return safe_json_parse(assistant_response)\n",
    "\n",
    "\n",
    "def safe_json_parse(model_text: str) -> Dict:\n",
    "    \"\"\"모델이 출력한 텍스트에서 JSON 블록만 추출해 안전하게 파싱합니다.\"\"\"\n",
    "    # 모델이 ```json ... ``` 코드 블록으로 응답하는 경우를 먼저 처리\n",
    "    match = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", model_text, re.DOTALL)\n",
    "    if match:\n",
    "        chunk = match.group(1)\n",
    "    else:\n",
    "        # 코드 블록이 없다면, 가장 바깥쪽의 중괄호({})를 기준으로 JSON을 찾음\n",
    "        start = model_text.find(\"{\")\n",
    "        end = model_text.rfind(\"}\")\n",
    "        if start != -1 and end != -1 and end > start:\n",
    "            chunk = model_text[start:end+1]\n",
    "        else:\n",
    "            raise ValueError(\"모델 응답에서 JSON 블록을 찾지 못했습니다:\\n\" + model_text)\n",
    "    \n",
    "    try:\n",
    "        # JSON 문자열을 파이썬 딕셔너리로 변환\n",
    "        return json.loads(chunk)\n",
    "    except json.JSONDecodeError:\n",
    "        # 마지막 항목 뒤에 쉼표가 붙는 등 흔한 JSON 오류를 보정하여 재시도\n",
    "        chunk = re.sub(r\",\\s*]\", \"]\", chunk)\n",
    "        chunk = re.sub(r\",\\s*}\", \"}\", chunk)\n",
    "        try:\n",
    "            return json.loads(chunk)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"JSON 파싱에 실패했습니다 (오류: {e}):\\n{chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3. 결과 정제 및 표준화 (Normalization)\n",
    "\n",
    "LLM이 생성한 JSON을 MFDS 표준에 맞게 다듬고, 'evidence'(증거) 항목을 더 정확하게 보강합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_fix_evidence(model_json: Dict, ocr_text: str) -> Dict:\n",
    "    \"\"\"\n",
    "    LLM이 생성한 JSON을 MFDS 표준에 맞게 정규화하고,\n",
    "    OCR 원문을 기반으로 증거(evidence)를 보강 및 수정합니다.\n",
    "    \"\"\"\n",
    "    # 1. 표준 명칭으로 정규화 (예: '계란', '난류' -> '계란(난류)')\n",
    "    normalized_allergens = []\n",
    "    seen = set()\n",
    "    for item in model_json.get(\"allergens_found\", []):\n",
    "        c = (item.get(\"canonical\") or \"\").strip()\n",
    "        if c in [\"계란\", \"난류\"]: c = \"계란(난류)\"\n",
    "        if \"조개\" in c: c = \"조개류\"\n",
    "        \n",
    "        if c in MFDS_CANON:\n",
    "            # 중복 제거\n",
    "            key = (c, tuple(sorted(item.get(\"evidence\", []))))\n",
    "            if key not in seen:\n",
    "                normalized_allergens.append(item)\n",
    "                seen.add(key)\n",
    "    \n",
    "    # 2. OCR 원문에서 더 정확한 증거(evidence) 찾기\n",
    "    \n",
    "    # '...함유' 라인에서 알레르겐 단어들 추출\n",
    "    contains_items = re.findall(r'([가-힣]+)\\s*함유', ocr_text)\n",
    "    \n",
    "    # 최종 결과물 구조 초기화\n",
    "    final_result = {\n",
    "        \"allergens_found\": [],\n",
    "        \"uncertain_mentions\": model_json.get(\"uncertain_mentions\", []),\n",
    "        \"notes\": model_json.get(\"notes\", \"\")\n",
    "    }\n",
    "    \n",
    "    for item in normalized_allergens:\n",
    "        canonical_name = item['canonical']\n",
    "        evidence = set(item.get('evidence', []))\n",
    "        \n",
    "        # '...함유' 라인에 표준명이 포함되어 있으면 증거로 추가\n",
    "        if canonical_name in contains_items:\n",
    "            evidence.add(canonical_name)\n",
    "        \n",
    "        # 원재료명 전체에서 표준명과 관련된 단어(동의어)들을 찾아 증거로 추가\n",
    "        synonyms = {\"우유\": [\"치즈\", \"버터\", \"크림\", \"유청\"], \"밀\": [\"소맥\"], \"대두\": [\"간장\", \"된장\", \"레시틴\"]}\n",
    "        for syn in synonyms.get(canonical_name, []):\n",
    "            if syn in ocr_text:\n",
    "                evidence.add(syn)\n",
    "\n",
    "        if evidence:\n",
    "            final_result[\"allergens_found\"].append({\n",
    "                \"canonical\": canonical_name,\n",
    "                \"evidence\": sorted(list(evidence), key=len)\n",
    "            })\n",
    "    \n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-4. 알레르겐 분석 파이프라인 실행 함수\n",
    "\n",
    "위에서 정의한 함수들을 순서대로 호출하여 전체 파이프라인을 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_allergen_pipeline(image_path: str = None, ocr_text: str = None, save_path: str = \"allergen_result.json\") -> Dict:\n",
    "    \"\"\"알레르겐 분석 파이프라인 전체를 실행합니다.\"\"\"\n",
    "    # OCR 텍스트가 입력되지 않았다면, 이미지 경로로 OCR 실행\n",
    "    if not ocr_text:\n",
    "        if not image_path:\n",
    "            raise ValueError(\"image_path 또는 ocr_text 중 하나는 반드시 제공해야 합니다.\")\n",
    "        ocr_text = detect_text_by_gcp(image_path)\n",
    "        if not ocr_text:\n",
    "            print(\"OCR 결과, 텍스트를 찾을 수 없어 분석을 종료합니다.\")\n",
    "            return {}\n",
    "\n",
    "    # LLM 추론 실행\n",
    "    print(\"LLM을 통해 알레르겐 정보를 추론합니다...\")\n",
    "    raw_json = llm_infer_to_json(ocr_text)\n",
    "\n",
    "    # 결과 정제 및 표준화\n",
    "    print(\"결과를 표준화하고 증거를 정리합니다...\")\n",
    "    final_result = normalize_and_fix_evidence(raw_json, ocr_text)\n",
    "\n",
    "    # 최종 결과를 JSON 파일로 저장\n",
    "    # save_path의 디렉터리가 없을 경우 생성\n",
    "    output_dir = os.path.dirname(save_path)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(final_result, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"✅ 알레르겐 분석 완료! 결과를 '{save_path}'에 저장했습니다.\")\n",
    "\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 파이프라인 2: 단순 텍스트 추출 (OCR → TXT)\n",
    "\n",
    "이미지에서 텍스트를 추출하여 `.txt` 파일로 저장하는 간단한 파이프라인입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_text_extraction_pipeline(image_path: str, save_path: str = None):\n",
    "    \"\"\"단순 텍스트 추출 파이프라인을 실행합니다.\"\"\"\n",
    "    # 1. OCR 실행\n",
    "    extracted_text = detect_text_by_gcp(image_path)\n",
    "\n",
    "    # 2. 추출된 텍스트가 있을 경우에만 파일 저장\n",
    "    if extracted_text:\n",
    "        output_path = save_path\n",
    "        \n",
    "        # 3. 저장 경로가 지정되지 않으면 이미지 파일명으로 자동 생성\n",
    "        if output_path is None:\n",
    "            # 예: 'sample.jpg' -> 'sample.txt'\n",
    "            base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            output_path = f\"{base_name}.txt\"\n",
    "        \n",
    "        # 4. UTF-8 인코딩으로 파일 저장 (한글 깨짐 방지)\n",
    "        output_dir = os.path.dirname(output_path)\n",
    "        if output_dir:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(extracted_text)\n",
    "        print(f\"✅ 텍스트 추출 완료! 결과를 '{output_path}'에 저장했습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 노트북에서 직접 실행하기\n",
    "\n",
    "이제 위에서 정의한 함수들을 직접 호출하여 파이프라인을 실행할 수 있습니다.  \n",
    "아래 예시 코드의 파일 경로를 실제 분석하고 싶은 이미지 파일 경로로 변경한 후 실행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 알레르겐 분석 파이프라인 실행 ---\n",
      "'차지예_009.jpg' 파일에서 텍스트를 추출합니다...\n",
      "텍스트 추출 완료.\n",
      "LLM을 통해 알레르겐 정보를 추론합니다...\n",
      "'Qwen/Qwen2.5-7B-Instruct' 모델을 로딩합니다. 잠시 기다려주세요...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06462a18aa1430297933bfd017be844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c94c42cdc54e14b566af0b71efc3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef090686762441ccadbea7f27808f1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b5857612fa4e1788be4de3c2ec4a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbeb4ab2abf242ee827af4d6a59f34db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63bb7dcbb1cb44c1a72c75e2ae72a10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3e806121164c2ab814f50466492e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16de3e91fff4ab5b27f3401e623d49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba23cffa29d14360a472f1f770be6977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433092559e6d4f47adc74ecc414960e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c98fd8f9fd041d4bb63998ca48246c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d922317befb94eaab98f89ec20a2920f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a269fed876a749d59dfbbf4c6c7829e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로딩 완료.\n",
      "결과를 표준화하고 증거를 정리합니다...\n",
      "✅ 알레르겐 분석 완료! 결과를 'my_allergen_result.json'에 저장했습니다.\n",
      "\n",
      "[최종 분석 결과]\n",
      "{\n",
      "  \"allergens_found\": [\n",
      "    {\n",
      "      \"canonical\": \"대두\",\n",
      "      \"evidence\": [\n",
      "        \"간장\",\n",
      "        \"대두\",\n",
      "        \"대두:외국산\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"canonical\": \"밀\",\n",
      "      \"evidence\": [\n",
      "        \"밀\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"uncertain_mentions\": [],\n",
      "  \"notes\": \"원재료명에서 대두와 밀이 함유됨을 확인.\"\n",
      "}\n",
      "-----------------------------------\n",
      "\n",
      "--- 단순 텍스트 추출 파이프라인 실행 ---\n",
      "'차지예_009.jpg' 파일에서 텍스트를 추출합니다...\n",
      "텍스트 추출 완료.\n",
      "✅ 텍스트 추출 완료! 결과를 'my_ocr_text.txt'에 저장했습니다.\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 실행 예시 ---\n",
    "\n",
    "# 분석할 이미지 파일 경로 (🚨 실제 파일 경로로 수정하세요)\n",
    "my_image_file = \"차지예_009.jpg\"\n",
    "\n",
    "# --- 예시 1: 알레르겐 분석 실행 ---\n",
    "if os.path.exists(my_image_file):\n",
    "    print(\"--- 알레르겐 분석 파이프라인 실행 ---\")\n",
    "    \n",
    "    allergen_result = run_allergen_pipeline(\n",
    "        image_path=my_image_file, \n",
    "        save_path=\"my_allergen_result.json\"\n",
    "    )\n",
    "    print(\"\\n[최종 분석 결과]\")\n",
    "    print(json.dumps(allergen_result, ensure_ascii=False, indent=2))\n",
    "    print(\"-\" * 35)\n",
    "else:\n",
    "    print(f\"'{my_image_file}' 경로에 이미지 파일이 없습니다. my_image_file 변수를 수정해주세요.\")\n",
    "\n",
    "\n",
    "# --- 예시 2: 단순 텍스트 추출 실행 ---\n",
    "if os.path.exists(my_image_file):\n",
    "    print(\"\\n--- 단순 텍스트 추출 파이프라인 실행 ---\")\n",
    "    run_text_extraction_pipeline(\n",
    "        image_path=my_image_file, \n",
    "        save_path=\"my_ocr_text.txt\"\n",
    "    )\n",
    "    print(\"-\" * 35)\n",
    "else:\n",
    "    print(f\"'{my_image_file}' 경로에 이미지 파일이 없습니다. my_image_file 변수를 수정해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 알레르겐 분석 파이프라인 실행 ---\n",
      "'김광무_147.jpg' 파일에서 텍스트를 추출합니다...\n",
      "텍스트 추출 완료.\n",
      "LLM을 통해 알레르겐 정보를 추론합니다...\n",
      "결과를 표준화하고 증거를 정리합니다...\n",
      "✅ 알레르겐 분석 완료! 결과를 'my_allergen_result.json'에 저장했습니다.\n",
      "\n",
      "[최종 분석 결과]\n",
      "{\n",
      "  \"allergens_found\": [\n",
      "    {\n",
      "      \"canonical\": \"밀\",\n",
      "      \"evidence\": [\n",
      "        \"밀\",\n",
      "        \"밀 함유\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"canonical\": \"대두\",\n",
      "      \"evidence\": [\n",
      "        \"대두, 밀, 우유, 닭고기, 쇠고기, 조개류(굴) 함유\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"canonical\": \"우유\",\n",
      "      \"evidence\": [\n",
      "        \"크림\",\n",
      "        \"버터\",\n",
      "        \"치즈\",\n",
      "        \"대두, 밀, 우유, 닭고기, 쇠고기, 조개류(굴) 함유\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"canonical\": \"닭고기\",\n",
      "      \"evidence\": [\n",
      "        \"대두, 밀, 우유, 닭고기, 쇠고기, 조개류(굴) 함유\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"uncertain_mentions\": [],\n",
      "  \"notes\": \"원재료명에서 알레르기 유발물질을 직접 확인하였습니다.\"\n",
      "}\n",
      "-----------------------------------\n",
      "\n",
      "--- 단순 텍스트 추출 파이프라인 실행 ---\n",
      "'김광무_147.jpg' 파일에서 텍스트를 추출합니다...\n",
      "텍스트 추출 완료.\n",
      "✅ 텍스트 추출 완료! 결과를 'my_ocr_text.txt'에 저장했습니다.\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 실행 예시 ---\n",
    "\n",
    "# 분석할 이미지 파일 경로\n",
    "my_image_file = \"김광무_147.jpg\"\n",
    "\n",
    "# --- 예시 1: 알레르겐 분석 실행 ---\n",
    "if os.path.exists(my_image_file):\n",
    "    print(\"--- 알레르겐 분석 파이프라인 실행 ---\")\n",
    "    \n",
    "    allergen_result = run_allergen_pipeline(\n",
    "        image_path=my_image_file, \n",
    "        save_path=\"my_allergen_result.json\"\n",
    "    )\n",
    "    print(\"\\n[최종 분석 결과]\")\n",
    "    print(json.dumps(allergen_result, ensure_ascii=False, indent=2))\n",
    "    print(\"-\" * 35)\n",
    "else:\n",
    "    print(f\"'{my_image_file}' 경로에 이미지 파일이 없습니다. my_image_file 변수를 수정해주세요.\")\n",
    "\n",
    "\n",
    "# --- 예시 2: 단순 텍스트 추출 실행 ---\n",
    "if os.path.exists(my_image_file):\n",
    "    print(\"\\n--- 단순 텍스트 추출 파이프라인 실행 ---\")\n",
    "    run_text_extraction_pipeline(\n",
    "        image_path=my_image_file, \n",
    "        save_path=\"my_ocr_text.txt\"\n",
    "    )\n",
    "    print(\"-\" * 35)\n",
    "else:\n",
    "    print(f\"'{my_image_file}' 경로에 이미지 파일이 없습니다. my_image_file 변수를 수정해주세요.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
